---
title: Toxic Content Monitoring
date: "2020-05"
template: "project"
draft: false
slug: "toxic-content-monitoring"
category: "Natural Language Processing"
tags:
  - "Natural Language Processing"
  - "Project"
description: ""
---
[![Alt text](/media/icons/GitHub-Mark-32px.png)](https://github.com/andronikmk/toxic-content-monitoring)

<div style="text-align: justify"> 

**Abstract:** In recent years, many articles have highlighted the toxic world of internet comments and intenet posts.
Reddit has announced its "anti-evil team" and YouTube has diasbled the comments section on videos featuring
children. The internet of today is a far cry from the early days when cyber-utopians heralded in a new era
of human collaboration and communication. While furfilling my role as a *Data Science Intern* at Big Armor, 
our team was taksed to come up with an application to be used by social workers to monitor and report potentially
harmful and toxic behavior. Systems exist to detect toxicity, suicidality, and other concenring behavior,
they are all either whole system programs or limited to a small set of topics.
The current model is a Bi-directional LSTM + GRU neural network made with PyTorch, assuming FastText vectorization. 
Considerable preprocessing is performed on the text before vectorization. The metrics used in evaluating
this model are F1 and ROC-AUC scores. 
 </div>

### Model
<div style="text-align: justify"> 
In recent years, many articles have highlighted the toxic world of internet comments and intenet posts.
Reddit has announced its "anti-evil team" and YouTube has diasbled the comments section on videos featuring
children. The internet of today is a far cry from the early days when cyber-utopians heralded in a new era
of human collaboration and communication. While furfilling my role as a *Data Science Intern* at Big Armor, 
our team was taksed to come up with an application to be used by social workers to monitor and report potentially
harmful and toxic behavior. Systems exist to detect toxicity, suicidality, and other concenring behavior,
they are all either whole system programs or limited to a small set of topics.
The current model is a Bi-directional LSTM + GRU neural network made with PyTorch, assuming FastText vectorization. 
Considerable preprocessing is performed on the text before vectorization. The metrics used in evaluating
this model are F1 and ROC-AUC scores. 
 </div>
 <img src="/media/toxic-content-monitoring/baselines-with-labels.png" alt="Baseline">



